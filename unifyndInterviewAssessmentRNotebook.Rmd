---
title: "Unifynd Interview Assessment (Data Analytics) R Notebook"
output:
  html_document:
    df_print: paged
    theme: lumen
    
author: Aarsh Batra
date: October 10, 2021
---

&nbsp;

&nbsp;

<hr>

&nbsp;

## File Structure

* To ensure that best practices are followed  (by design), this entire task is executed as a R package. 

* This is why I have shared the entire package directory with you as my submission for this data task.

* In the directory, there is a .RProj (R project file). If you open it in R Studio (R Studio is required for running this), you will have all the relevant environment needed for you to run this R Markdown Notebook (named: unifyndInterviewAssessmentRNotebook.Rmd). Note that this file has a .Rmd extension.

* This R notebook contains all the code, output and answers for all of the 7 questions(and its sub-parts) in the task. This R Notebook (.Rmd file) is present in the root of the package directory. 

* Also all the helper (.R) scripts, other than this .Rmd file, can be found in the **R** sub-directory.

* Just make sure that you have all the R packages (mentioned in the "load_libraries" chunk in this R Notebook below) installed on your system. 

* Also, make sure that your paths are set as per your system. I have used relative paths in the code, but still it is good to have this as a Sanity check before running the code.

* Once you have followed all of the above steps, please continue reading below on how to use this R Notebook.

&nbsp;

<hr>

## How to use this R Markdown notebook? 

* You can preview this notebook using the **Preview** button, which will show you rendered HTML copy of the contents of the editor. 

* The other option is to knit this notebook into a neat PDF, which you can do using the **Knit** button.
 
* Unlike **Knit**, **Preview** does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed. So, when you use **Preview**, please make sure that you have once run all the chunks of code in the editor. Once you run all chunks and then preview, the resulting html output will show all code and all output (plots, tables, etc).

* This notebook contains all code, output and answers, for all of the 7 Questions (and all its sub-parts). By that I mean, it also contain answers to theory questions (ones in which I am asked about my observations and insights, e.g. Q7:part-3).

* I have also attached a complete pre-knitted PDF (with all code, output, answers) in my submission files (along side this .Rmd file).

* Feel free to reach out to me at **aarshbatra.in@gmail.com**/8800592799 if you have any questions or run into any problems. I will quickly troubleshoot it for you.

&nbsp;

<hr>

## Initial Setup

```{r metadata, echo=TRUE, message=FALSE, warning=FALSE}

# metadata---------------------------------------------------------------------
# author: Aarsh Batra
# Start Date: October 07, 2021
# R version: 4.1.1 (2021-08-10)
# nickname: Kick Things
# Platform: x86_64-w64-mingw32 
# arch: x86_64
# Running under: Windows 10 x64 (build 18363)
# R Studio version info: 2021.09.0+351 "Ghost Orchid"
# e-mail: aarshbatra.in@gmail.com

```


```{r load-libraries, message=FALSE, warning=FALSE, include=FALSE}

# load libraries---------------------------------------------------------------

library(tidyverse)
library(knitr)
library(devtools)
library(stringr)
library(tidyr)
library(dplyr)
library(skimr)
library(magrittr)
library(data.table)
library(lubridate)
library(roxygen2)
library(testthat)
library(ggplot2)
library(readr)
library(readxl)
```

```{r load-entire-package, echo=TRUE, message=FALSE, warning=FALSE}

# loading the entire package--------------------------------------------------

devtools::load_all()

```


```{r read-raw-datasets, echo=TRUE, message=FALSE, warning=FALSE}

# read in raw .xlsx datasets into R--------------------------------------------

coupon_transactions_raw <- read_raw_xlsx_data("couponTransactions.xlsx")
 
 customer_scans_raw <- read_raw_xlsx_data("customerScans.xlsx")
                                          
 customer_user_raw <- read_raw_xlsx_data("customerUser.xlsx")
```

&nbsp;

<hr>

## Exploratory Data Analysis

* First, I will explore the dataset after which I will proceed to
answering the questions. Everything inside the below chunk of code is for exploration only. I have commented out most of the exploratory code, if you'd like to see what it does, you may uncomment it. None of the variable from the below chunk exploratory code are used after this chunk of code. Still, I have included some of the main exploratory code output below. 

&nbsp;

```{r exploratory-data-analysis-question-wise}

# exploring coupon_transaction_raw dataset-------------------------------------

# View(coupon_transactions_raw)

# getting a basic summary
skimr::skim(coupon_transactions_raw)

# # number of unique customers
#   length(unique(coupon_transactions_raw$customerId)) # 14979
# 
# # number of unique couponUnlock dates
#   length(unique(coupon_transactions_raw$couponUnlockDate)) # 291
# 
# # number of unique couponId's
# length(unique(coupon_transactions_raw$couponId)) # 328


# exploring customer_scans_raw dataset-----------------------------------------

# View(customer_scans_raw)

# skim customer_scans_raw dataset
skimr::skim(customer_scans_raw)

# # max amount for billTotal column
# max(customer_scans_raw$billTotal) # why is this too big? look into this.
# 
# # number of unique customers
# length(unique(customer_scans_raw$customerId))
# 
# # number of unique scan log ids
# length(unique(customer_scans_raw$scanlogId))
# 
# # number of unique stores
# length(unique(customer_scans_raw$storeName))
# 
# # store with the maximum bill total
# customer_scans_raw %>% 
#   filter(billTotal == max(billTotal)) %>%
#   select(storeName)
# 

# exploring customer_user_raw data---------------------------------------------

# View(customer_user_raw)

# skim customer_user_raw dataset
skimr::skim(customer_user_raw)

# # number of unique customers
# unique(length(customer_user_raw$customerId))
# 
# # number of unique tierId's 
# length(unique(customer_user_raw$tierId))
# 

# wrapping up exploratory data analysis with a few more queries-----------------
colnames_for_datasets_list <- list(coup_trans_col = colnames
                                   (coupon_transactions_raw),
                                cust_scans_col = colnames(customer_scans_raw), 
                              cust_user_col = colnames(customer_user_raw))

# one common column between coupon_transactions_raw and customer_scans_raw
sum(colnames_for_datasets_list[[2]] %in% 
      colnames_for_datasets_list[[1]])  # customerId

# two common columns between customer_scans_raw and customer_user_raw
sum(colnames_for_datasets_list[[3]] %in% 
      colnames_for_datasets_list[[2]]) # customerId, createdAt

# one common column between customer_user_raw and coupon_transactions_raw
sum(colnames_for_datasets_list[[3]] %in% 
      colnames_for_datasets_list[[1]]) # customerId
```
&nbsp;

<hr>

## Let's get to the answers:

&nbsp;

### Code and answer for Q1

#### **Question 1**: How many Users have logged in after 1st September 2020 till date? How many of those have Signed up in September 2019?

&nbsp;

#### Code

&nbsp;

```{r Q1-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# number of users who have logged in after 1st September 2021, till date

customer_user_raw_Q1_subset <- customer_user_raw %>%
  select(customerId, createdAt, lastLogin, tierId) %>%
  filter(lastLogin > lubridate::as_datetime("2020-09-01")) %>%
  distinct()
 
customer_user_raw_Q1_subset

# number of users looged in after Sep 2021.
 num_users_log_in_after_sep2021 <- customer_user_raw_Q1_subset %>%
   nrow()                                
 
 num_users_log_in_after_sep2021 # answer to Q1Part-1 = 10,323 users


# Of the above 10,323 users, how many signed up in September, 2019.

 num_user_logInAfterSep2021_signedUpInSep2019 <- customer_user_raw_Q1_subset %>%
  dplyr::filter(lubridate::month(createdAt) == 09, lubridate::year(createdAt) == 2019) %>%
   nrow()

 num_user_logInAfterSep2021_signedUpInSep2019 # answer to Q2Part-2 = 209 users

```

&nbsp;

#### **Answer 1 (part 1)**: `r num_users_log_in_after_sep2021` users have logged in after 1st September 2021, till date.

&nbsp;

#### **Answer 1 (part 2)**: Of the `r num_users_log_in_after_sep2021` users from part 1 above, `r num_user_logInAfterSep2021_signedUpInSep2019` users have signed up in September 2019.

&nbsp;

* Please Note: In the absence of a data dictionary describing what each column 
means, I have made the following assumptions about the columns in the 
**customer_users_raw** dataset: I have assumed that  the **createdAt** column 
in the corresponds to the sign_up date column, and the **lastLogin** corresponds
to the login column. This might seem obvious, but it is still worth mentioning.

&nbsp;

<hr>

### Code and answer for Q2

&nbsp;

#### **Question 2:** How many users have earned points more than 2000?

&nbsp;

```{r Q2-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# sanity check
sum(is.na(customer_user_raw$earnedPoints))

# Number of users who have earnedPoints more than 2000
num_users_earned_points_more_than_2000 <- customer_user_raw %>%
  dplyr::filter(earnedPoints > 2000) %>% 
  distinct() %>%
  nrow()                          

 num_users_earned_points_more_than_2000            # answer to Q2 = 1261

```
&nbsp;

#### **Answer 2:** `r num_users_earned_points_more_than_2000` users have earned points more than 2000.

&nbsp;

<hr>

### Code and answer for Q3

&nbsp;

#### **Question 3: ** From which stores has customer id ‘83’ scanned bills in February 2020?

&nbsp;

```{r Q3-answer-code, echo=TRUE, message=FALSE, warning=FALSE}
customer_scans_raw_Q3_subset <- customer_scans_raw %>%
  filter(customerId == 83, lubridate::month(createdAt) == 02, 
         lubridate::year(createdAt) == 2020) %>%
  dplyr::select(customerId, storeName, createdAt, image) %>%
  dplyr::group_by(storeName) %>%
  dplyr::summarise(numBillsScanned = length(unique(image))) %>%
  dplyr::mutate(customerId = 83, month = "February, 2020") %>%
  dplyr::select(customerId, everything())

```

&nbsp;

#### **Answer to Q3:** Below is a table, which lists the stores from which customer id "83" scanned bills in February, 2020. It also lists the total number of unique bills scanned by customer Id "83" for each store. This information is useful in case more than one bill is scanned per store. 

&nbsp;

```{r Q3-answer-table, echo=TRUE, message=FALSE, warning=FALSE}
knitr::kable(customer_scans_raw_Q3_subset)
```

&nbsp;

* Please Note: In the absence of a data dictionary describing what each column 
means, I have made the following assumptions about the columns in the 
**customer_scans_raw** dataset: I have assumed that  the **createdAt** column 
in this dataset corresponds to the date at which the scan was created, and the 
**billDate** column corresponds to date on which the bill was generated. 
Also, there is a date within the image file names, because we do not know, what
that date represents, I haven't extracted or used it.

&nbsp;

<hr>

### Code and answer for Q4 

&nbsp;

#### **Question 4**: How many unique users unlocked coupons on 10th September 2020?

&nbsp;

```{r Q4-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# creating a coupon_transactions_raw with duplicate rows removed
coupon_transactions_raw_unique <- coupon_transactions_raw[!duplicated(coupon_transactions_raw), ]

# dataset for unique users who unlocked coupons on 10th September 2020
coupon_transactions_raw_Q4_subset <- coupon_transactions_raw_unique %>%
  filter(couponUnlockDate == lubridate::as_datetime("2020-09-10")) %>%
  group_by(customerId) %>%
  summarise(numUniqueCouponsUnlocked = length(unique(couponId))) %>%
  mutate(dateOnWhichCouponUnlocked = "September 10, 2020")

# number of unique users who unlocked coupons on 10th September 2020
num_unique_users_unlocked_coupons_on_Sep102020 <- 
  nrow(coupon_transactions_raw_Q4_subset)     # answer to Q4 = 34 unique users.


```

&nbsp;

#### **Answer to Q4:** `r num_unique_users_unlocked_coupons_on_Sep102020` unique users unlocked coupons on September 10, 2021. Below presented is a table that lists these unique users and also shows the number of unique coupons unlocked by each one of them on September 10, 2021.

&nbsp;

```{r Q4-answer-table, echo=TRUE, message=FALSE, warning=FALSE}

# summary table
knitr::kable(coupon_transactions_raw_Q4_subset)

```

&nbsp;

<hr>

### Code and answer for Q5

&nbsp;

#### **Question 5: ** Create a pivot table as mentioned in the question description in the [Question PDF file](https://github.com/AarshBatra/UnifyndInterviewAssessment/blob/master/Interview%20Assignment%20_%20Data%20Analytics.pdf)

&nbsp;

```{r Q5-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# sanity checks (for understanding purposes only, these sanity check variables
# are not used in code)
foo <- dplyr::left_join(x = coupon_transactions_raw, y = customer_user_raw, by = c("customerId" = "customerId"))
sum(coupon_transactions_raw$customerId %in% customer_user_raw$customerId)
sum(!(customer_user_raw$customerId %in% coupon_transactions_raw$customerId))        

foo1Ind <- customer_user_raw$customerId %in% coupon_transactions_raw$customerId
foo1Val <- customer_user_raw$customerId[foo1Ind]
nrow(filter(coupon_transactions_raw, customerId %in% foo1Val))


# First: left_join the "customer_user_raw" and "coupon_transaction_raw_unique" data by the "customerId" column as a KEY

customer_user_coupon_join_Q5 <- dplyr::left_join(x = customer_user_raw, y = coupon_transactions_raw_unique, by = "customerId")

# removing duplicate rows
customer_user_coupon_join_Q5_unique <-  customer_user_coupon_join_Q5[!duplicated(customer_user_coupon_join_Q5), ]

# create Pivot table, by using tierId  as the "group" column
pivot_table_by_tier_Q5 <- customer_user_coupon_join_Q5_unique %>%
  dplyr::group_by(tierId) %>%
  dplyr::summarise(numUniqueUsersInEachTier = length(unique(customerId)),
            totalCouponsUnlocked = sum(!is.na(couponUnlockDate)),
            averageEarnedPoints = mean(earnedPoints, na.rm = TRUE), 
            averageBurnedPoints = mean(burnedPoints, na.rm = TRUE))


```

&nbsp;

#### **Answer 5:** Pivot Table for Q5

&nbsp;

```{r Q5-answer-pivot-table }
knitr::kable(pivot_table_by_tier_Q5)
```

&nbsp;

<hr>

### Code and answer for Q6

#### **Question 6:** Create a cohort of users with the following conditions (Scan Count > 4 && Coupon Transaction Count > 2) and answer the following questions:

  * 1. What’s the tier distribution of these users?
  * 2. What’s the gender distribution of these users?
  * 3. Which 5 stores have these users scanned the most from?
  * 4. Which source has the most users coming from in this cohort?
  * 5. Observe the behaviour of this cohort and write your observations and 
       insights.

&nbsp;

#### Getting the number and id's of customers that belong to the cohort whose scanCount > 4 and couponTransactionCount > 2

&nbsp;
       
```{r Q6-answer-get-cohort, echo=TRUE, message=FALSE, warning=FALSE}

# get a vector of customerId's that satisfy the cohort conditions--------------
  
# customers with scan count > 4
customer_scans_raw_Q6_subset <- customer_scans_raw %>%
group_by(customerId) %>%
summarise(scanCount = sum(!is.na(unique(scanlogId)))) %>%
filter(scanCount > 4) 

# removing duplicates
customer_scans_raw_Q6_subset_unique <- customer_scans_raw_Q6_subset[
  !duplicated(customer_scans_raw_Q6_subset), ]

# For the customers whose scan count is greater than 4, select those whose
# coupon transaction count > 2.

# creating a subset of data that corresponds to those customers whose 
# scan count > 4
coupon_transactions_raw_Q6_subset <- coupon_transactions_raw %>%
  filter(customerId %in% customer_scans_raw_Q6_subset_unique$customerId) 

# removing any duplicate rows
coupon_transactions_raw_Q6_subset_unique <-  coupon_transactions_raw_Q6_subset[!duplicated
            (coupon_transactions_raw_Q6_subset), ]

# dataset containing customers whose "scanCount" > 4 and couponTransactionCount
# is > 2
coupon_transactions_raw_Q6_subset_unique_finCohort <- coupon_transactions_raw_Q6_subset_unique %>% 
  group_by(customerId) %>%
  summarise(couponTransactionCount = sum(!is.na(couponUnlockDate))) %>%
  filter(couponTransactionCount > 2)

# putting the cohort customers (that satisfy the cohort definition) into a 
# vector

cohort_customers <- coupon_transactions_raw_Q6_subset_unique_finCohort$customerId


```

&nbsp;

#### Given the above calculations, the cohort whose scanCount > 4 and couponTransactionCount > 2, contain a total of `r length(cohort_customers)` customers.These customers are stored in the vector named **cohort_customers**. Now, I will use this information to answer parts 1 to 5 of Q6. For each part, I will first present the code and then its answer (figure/table/etc).

&nbsp;

<hr>

#### **Code and Answer to Question 6: Part-1**

&nbsp;

#### **Q6(Part-1):** What is the tier distribution of Cohort users?

&nbsp;

```{r Q6-answer-part1, echo=TRUE, message=FALSE, warning=FALSE}

# making sure that we are only using users that satisfy cohort definition
tier_dist_cohort_users <- customer_user_raw %>%
  filter(customerId %in% cohort_customers) 

# removing duplicate rows (if any)
tier_dist_cohort_users <- tier_dist_cohort_users[!duplicated(tier_dist_cohort_users), ]

# grouping and summarising by tierId
tier_dist_cohort_users <- tier_dist_cohort_users %>%
  group_by(tierId) %>%
  summarise(countOfUsers = n()) %>%
  mutate(percentOfUsers = (countOfUsers/sum(countOfUsers, na.rm = TRUE))*100)

# plot: tier distribution of cohort users  
tier_dist_cohort_users_plot <-  tier_dist_cohort_users %>%
  ggplot(mapping = aes(x = tierId, y = countOfUsers)) +
  geom_col(width = 0.5) +
  scale_y_continuous(breaks = seq(0, 500, by = 30)) +
  geom_text(mapping = aes(label = countOfUsers), position=position_dodge(width=0.9), vjust=-0.25) + ggtitle("Tier distribution of Cohort users") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

&nbsp;

#### **Answer: Q6(Part-1):** Below is a table and a bar graph of of the tier distribution of cohort users

&nbsp;

```{r Q6-answer-part1-tabGraph, echo=TRUE, message=FALSE, warning=FALSE}

# plot: tier distribution of cohort users
tier_dist_cohort_users_plot

# Table: tier distribution of cohort users
knitr::kable(tier_dist_cohort_users)

```

&nbsp;

<hr>

#### **Q6(Part-2):** What the gender distribution of Cohort users?

&nbsp;

```{r Q6-answer-part2, echo=TRUE, message=FALSE, warning=FALSE}

# making sure that we are only using users that satisfy cohort definition
gender_dist_cohort_users <- customer_user_raw %>%
  filter(customerId %in% cohort_customers) 

# removing duplicate rows (if any)
gender_dist_cohort_users <- gender_dist_cohort_users[!duplicated(gender_dist_cohort_users), ]

# grouping and summarising by gender
gender_dist_cohort_users <- gender_dist_cohort_users %>%
  group_by(gender) %>%
  summarise(countOfUsers = n()) %>%
  mutate(percentOfUsers = (countOfUsers/sum(countOfUsers, na.rm = TRUE))*100)

# plot: gender distribution of cohort users
gender_dist_cohort_users_plot <-  gender_dist_cohort_users %>%
  ggplot(mapping = aes(x = gender, y = countOfUsers)) +
  geom_col(width = 0.5) +
  scale_y_continuous(breaks = seq(0, 500, by = 30)) +
  geom_text(mapping = aes(label = countOfUsers), position=position_dodge(width=0.9), vjust=-0.25) + ggtitle("Gender distribution of Cohort users") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))


```

&nbsp;

<hr>

#### **Answer: Q6(Part-2):** Below is a table and a bar graph of of the gender distribution of cohort users.

* Please note: In this cohort, of the total `r length(cohort_customers)` there are `r nrow(customer_user_raw %>% filter(customerId %in% cohort_customers, gender == "NULL"))` customers whose value for gender column is "NULL" in the dataset. Also, there are `r nrow(customer_user_raw %>% filter(customerId %in% cohort_customers, is.na(gender)))` customers whose value for the gender column is "NA". In the gender distribution below (both in table and in graph), I have kept them, instead of filtering them out, as it is good to have a visual representation 
of these missing values.

&nbsp;

```{r Q6-answer-part2-tabGraph, echo=TRUE, message=FALSE, warning=FALSE}

# plot: gender distribution of cohort users
gender_dist_cohort_users_plot

# table: gender distribution of cohort users
knitr::kable(gender_dist_cohort_users)

```

&nbsp;

<hr>

#### **Q6(Part-3):** Which 5 stores have these users scanned the most from?

&nbsp;

```{r Q6-answer-part3, echo=TRUE, message=FALSE, warning=FALSE}

# making sure that we are only using users that satisfy cohort definition
cohort_users_5_stores_scanned_most_from <- customer_scans_raw %>% 
  filter(customerId %in% cohort_customers) 

# removing duplicate rows (if any)
cohort_users_5_stores_scanned_most_from <- cohort_users_5_stores_scanned_most_from[!duplicated(cohort_users_5_stores_scanned_most_from), ]

# grouping and summarising by Store name
cohort_users_5_stores_scanned_most_from <- cohort_users_5_stores_scanned_most_from %>%
  group_by(storeName) %>%
  summarise(scansCount = n()) %>% 
  slice_max(scansCount, n = 5) %>%
  mutate(scansPercentage = (scansCount/sum(scansCount, na.rm = TRUE))*100)



# plot: 5 stores the user scanned the most from
cohort_stores_top5_scanned_most_plot <-  
  cohort_users_5_stores_scanned_most_from %>%
  dplyr::arrange(scansCount) %>%
  ggplot(mapping = aes(x = storeName, y = scansCount)) +
  geom_col(width = 0.5) +
  scale_y_continuous(breaks = seq(0, 1800, by = 100)) +
  geom_text(mapping = aes(label = scansCount), position=position_dodge(width=0.9), vjust=-0.25) + ggtitle("5 stores users scanned most from") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

&nbsp;

#### **Answer: Q6(Part-3):** Below is a table and a bar graph for the 5 stores from which the cohort users scanned the most.

&nbsp;

```{r Q6-answer-part3-tabGraph, echo=TRUE, message=FALSE, warning=FALSE}

# plot: 5 stores customers scanned most from
cohort_stores_top5_scanned_most_plot

# table: 5 stores customers scanned most from
knitr::kable(cohort_users_5_stores_scanned_most_from)


```

&nbsp;

<hr>

#### **Q6(Part-4):** Which source has the most users coming from in this cohort?

&nbsp;


```{r Q6-answer-part4, echo=TRUE, message=FALSE, warning=FALSE}

# making sure that we are only using users that satisfy cohort definition
cohort_source_users <- customer_user_raw %>% 
  filter(customerId %in% cohort_customers)

# removing duplicate rows (if any)
cohort_source_users <- cohort_source_users[!duplicated(cohort_source_users), ]

# grouping and summarizing by "source" column
cohort_source_users <- cohort_source_users %>%
  group_by(source) %>%
  summarise(userCount = n()) %>%
  mutate(userPercentage = (userCount/sum(userCount, na.rm = TRUE))*100)

# Answer table for Q6 Part 4: Which source has the most users coming from?
cohort_source_most_users_table <- cohort_source_users %>%
  slice_max(userCount, n = 5)

# plot: Top 5 sources from which most users are coming
cohort_source_most_users_table_plot <-  
  cohort_source_most_users_table %>%
  dplyr::arrange(userCount) %>%
  ggplot(mapping = aes(x = source, y = userCount)) +
  geom_col(width = 0.5) +
  scale_y_continuous(breaks = seq(0, 1800, by = 100)) +
  geom_text(mapping = aes(label = userCount), position=position_dodge(width=0.9), vjust=-0.25) + ggtitle("Top 5 sources from which most users are coming") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

&nbsp;

#### **Answer: Q6(Part-4):** 

* Below is a table and a bar graph for the top 5 sources from which most of the users are coming in this cohort. 

* The question asks to list the top source from which most users are coming. As is clear from the bar graph below, most of the source information is missing (NA, NULL).

* Instead of removing them from the plot, I have kept these intentionally as I always find it useful to have a visual representation of what is missing from the dataset. Otherwise, many times, it simply gets missed from analysis.

* But, if we ignore the `r filter(cohort_source_most_users_table, is.na(source))$userCount` NA values, and `r filter(cohort_source_most_users_table, source == "NULL")$userCount` NULL values, the source from which the highest number of users are coming is `r cohort_source_most_users_table$source[3]`, with total number of users = `r cohort_source_most_users_table$userCount[3]`.

* So, the answer for Question 6(part-4) is: `r cohort_source_most_users_table$source[3]` is the source from which `r cohort_source_most_users_table$userCount[3]` users are coming.

&nbsp;

```{r Q6-answer-part4-tabGraph, echo=TRUE, message=FALSE, warning=FALSE}

# plot: Top 5 sources from which most users are coming
cohort_source_most_users_table_plot

# table: Top 5 sources from which most users are coming
cohort_source_most_users_table
```

&nbsp;

<hr>

#### A few other graphs to help better understand Q6:

&nbsp;

```{r Q6-extra-graphs, echo=TRUE, message=FALSE, warning=FALSE}

# tmp dataset for generating graphs
foo_user_tmp <- customer_user_raw %>%
  filter(customerId %in% cohort_customers)

foo_scans_tmp <- customer_scans_raw %>%
  filter(customerId %in% cohort_customers,
         storeName %in% cohort_users_5_stores_scanned_most_from$storeName)


# gender distribution within tiers
foo_user_tmp %>% 
  ggplot(mapping = aes(x = tierId, fill = gender)) +
  geom_bar(position = "dodge") + 
  ggtitle("gender distribution within tiers")

# billTotal distribution for top 5 stores users scanned most from
foo_scans_tmp %>% 
  ggplot(mapping = aes(x = storeName, y = billTotal)) +
  scale_y_log10() +
  geom_boxplot() + 
  xlab("log10(billTotal)") +
  ggtitle("billTotal (in log scale base 10) distribution for top 5 stores users scanned most from")

  
```


&nbsp;

<hr>

#### **Q6(Part-5):** Observe the behaviour of this cohort and write your observations and insights.

&nbsp;

#### **Answer: Q6(Part-5):** Observations and Insights:

* In this cohort, more than 75% of the total number of users live in tier-2 alone. 86% of the users live in tier-1 and tier-2 combined. 98% of the users live in tier-1, tier-2 and tier-3 combined. Almost no one lives in Tier-4 and Tier-5. This shows that this particular cohort mostly resides in Urban high population centers. **[Refer plot: Tier distribution of Cohort users plot]**.

* Around 70% of the users in this cohort are Males and 30% females. But, almost 15% of data on 'gender' is missing (either NA, or NULL). **[Refer plot: Gender distribution of cohort users plot]**.
  
  *The sex ratio for India according to [this article](https://www.census2011.co.in/sexratio.php) is 1.06 males for every 1 female. This means that for every 1000 females there are 1060 males. 
  
  * The sex ratio in our cohort (with missing gender data) is 2.47 males for 1 female, which would mean that for every 1000 females, there are 2,470 males. That does not seem right. Gender gap will probably decrease if missing data becomes available.
  
* Almost all of the missing data, comes from either tier-1, tier-2 or tier-3. This makes sense as that is where most of the users reside. **[Refer plot: Gender distribution within tiers plot]**

* Gender gap within tiers is similar to the gender gap in the  overall data. But, as mentioned earlier, this is probably because a lot of data on gender is missing. **[Refer plot: Gender distribution within tiers plot]**

* Users scanned the most from Big Bazaar. Of the total number of scans count in the top 5 stores (from which users scanned the most), more than half of those scans are for Big Bazaar. The next big chunk is taken by the Lifestyle store, followed by Luxe, Latt Liv and Miniso. **[Refer plot: 5 stores users scanned most from plot]**

* Big Bazaar and Lifestyle probably being the most pocket friendly, were the ones that users scanned the most. But, for more expensive (relatively) stores like Luxe, Miniso, Latt Liv we see lesser number of scans (compared to Big Bazaar). **[Ref plot: 5 stores users scanned most from plot]**

* The source from which most users are coming is NPBPROMO3, the next best top sources also are versions of this NPBPROMO class. This means that these are probably the best places for shop owners to invest their money in to attract customers.**[Refer plot: Top 5 sources from which most users are coming]**

* **[Refer plot: billTotal distribution for top 5 stores users scanned most from]**
 
  * We see that average values for billTotal for all stores is approximately the same. For big bazaar the average is the lowest, which is expected.
  
  * There is a high amount of variation in the distribution of billTotal for both Big Bazaar and Lifestyle. This is probably because of the variety of products they sell. That also explains the most number of bills being scanned in these stores, as they attract people from all tiers.
  
  * Their is very little amount of variation in the billTotal of Miniso store, which probably hints at the streamlined product lines that it has for people who can afford to spend more, probably mostly tier-1 and tier-2 people.
  
  * In all stores, except Luxe, there is small amount if variation around the average, or in other words, the Inter Quartile Range is small. This tells us that, except for Luxe (which has a large amount of variation in its billTotal), all other stores have billTotals that stay close to the average billTotal amount.


&nbsp;

<hr>

### Code and answer for Q7

#### **Question 7:** Month on Month comparison:

* 1) From the given tables derive this table(execute joins with other  tables if      required).
  
* 2) Analyse the change in September Vs October and highlight/mention the            highest changes for each tier
  
* 3) Observe the metrics and write your observations and insights

&nbsp;

#### **Code and Answer to Question 7: Part-1**

&nbsp;

&nbsp;

#### **Q7(Part-1):** From the given tables derive this table(execute joins with other tables if required)

#### Code

```{r Q7-answer-part1, echo=TRUE, message=FALSE, warning=FALSE}

# sanity checks
sum(customer_scans_raw$customerId %in%
  customer_user_raw$customerId) == length(customer_scans_raw$customerId)

sum(customer_user_raw$customerId %in%
  customer_scans_raw$customerId)

# performing a left-join and combining the "customer_user_raw" data with "customer_scans_raw data" 

customer_user_scans_join_Q7 <- dplyr::left_join(
  select(customer_user_raw, -createdAt), customer_scans_raw, by = "customerId")

# removing duplicate rows (if any) unlikely that we will see duplicate rows here as there are a lot of columns
customer_user_scans_join_Q7 <- customer_user_scans_join_Q7[!duplicated(customer_user_scans_join_Q7), ]

# adding 2 columns, a month and a year column to the customer_user_scans_join_Q7 dataset------------------------------------------------------------------------ 

# we will derive these column is derived from the "createdAt" column of the joined dataset. The "createdAt" column in the joined dataset, contains the date at which the scan was created.

# Note that, there was a "createdAt" column in the customer_user_raw dataset, # although the name is the same, that refers to the date at which the customer signed up. To avoid confusion, I removed that column, while joining rhe dataset. 
# So, the "createdAt" in the joined dataset, corresponds to the "createdAt" column of the "customer_scans_raw" data. It should be interpreted as, it would have been interpreted in the scans dataset, i.e. it is the date at which the scan was created.

# From this column, I will derive two new columns and add it to the joined data set before.

customer_user_scans_join_Q7 <- customer_user_scans_join_Q7 %>%
  mutate(scanCreatedMonth = lubridate::month(createdAt), 
         scanCreatedYear = lubridate::year(createdAt))

# left_join customer_user_scans_join_Q7 dataset with coupon_transactions_raw_unique--------------------------------------

# sanity checks before joining

sum(coupon_transactions_raw_unique$customerId %in% 
  customer_user_scans_join_Q7$customerId)

sum(customer_user_scans_join_Q7$customerId %in% coupon_transactions_raw_unique$customerId)

# left-joining after sanity check complete
customer_user_scans_join_Q7_join_coupTransRawUniq <- 
  left_join(customer_user_scans_join_Q7, coupon_transactions_raw_unique, 
            by = "customerId")



# Create parts of table separately and then bind them together------------------------------------------------------------

# Unique users (by TierId) who scanned in Sep 2020-----------------------

# selecting relevant columns
uniq_users_byTier_scanned_Sep2020 <- customer_user_scans_join_Q7 %>% 
  select(customerId, tierId, scanCreatedMonth, scanCreatedYear, createdAt)

# removing duplicates
uniq_users_byTier_scanned_Sep2020 <- uniq_users_byTier_scanned_Sep2020[!duplicated(uniq_users_byTier_scanned_Sep2020), ]

# uniq users by tier who scanned in sep 2020 summary table
uniq_users_byTier_scanned_Sep2020 <- uniq_users_byTier_scanned_Sep2020 %>%
  filter(scanCreatedMonth %in% c(9), scanCreatedYear %in% c(2020), !is.na(createdAt)) %>%
  group_by(tierId) %>%
  summarise(uniqUsersWhoScannedIn_Sep2020 = length(unique(customerId)))

# adding a row for tier-5 and filling it with NA as there is no data in tier-5
uniq_users_byTier_scanned_Sep2020 <- dplyr::add_row(
  uniq_users_byTier_scanned_Sep2020, tierId = 5, uniqUsersWhoScannedIn_Sep2020 = NA)


# Unique users (by tierId) who scanned in Oct 2020-----------------------------------

# selecting relevant columns
uniq_users_byTier_scanned_Oct2020 <- customer_user_scans_join_Q7 %>% 
  select(customerId, tierId, scanCreatedMonth, scanCreatedYear, createdAt)

# removing duplicates
uniq_users_byTier_scanned_Oct2020 <- uniq_users_byTier_scanned_Oct2020[!duplicated(uniq_users_byTier_scanned_Oct2020), ]

# Unique users (by tierId) who scanned in Oct 2020 summary table
uniq_users_byTier_scanned_Oct2020 <- uniq_users_byTier_scanned_Oct2020 %>%
  filter(scanCreatedMonth %in% c(10), scanCreatedYear %in% c(2020), !is.na(createdAt)) %>%
  group_by(tierId) %>%
  summarise(uniqUsersWhoScannedIn_Oct2020 = length(unique(customerId)))


# Number of bills scanned (Image) in Sep 2020---------------------------------------

# selecting relevant columns
num_bills_scanned_Sep2020_byTier <- customer_user_scans_join_Q7 %>%
  select(tierId, customerId, scanCreatedMonth, scanCreatedYear, image)

# removing duplicates
num_bills_scanned_Sep2020_byTier <- num_bills_scanned_Sep2020_byTier[!duplicated(num_bills_scanned_Sep2020_byTier), ]

# Number of bills scanned (Image) in Sep 2020 summary table
num_bills_scanned_Sep2020_byTier <-  num_bills_scanned_Sep2020_byTier %>%
  filter(scanCreatedMonth %in% c(9), scanCreatedYear %in% c(2020), !is.na(image)) %>%
  group_by(tierId) %>%
  summarise(numBillsScannedIn_Sep2020 = length(image))

# adding a row for tier-5 and filling it with NA as there is no data in tier-5
num_bills_scanned_Sep2020_byTier <- dplyr::add_row(num_bills_scanned_Sep2020_byTier, 
                tierId = 5, numBillsScannedIn_Sep2020 = NA)


# Number of bills scanned (Image) in Oct 2020-------------------------------------------

# selecting relevant columns
num_bills_scanned_Oct2020_byTier <- customer_user_scans_join_Q7 %>%
  select(tierId, customerId, scanCreatedMonth, scanCreatedYear, image)

# removing duplicates
num_bills_scanned_Oct2020_byTier <- num_bills_scanned_Oct2020_byTier[!duplicated(num_bills_scanned_Oct2020_byTier), ]

# Number of bills scanned (Image) in Oct 2020 summary table
num_bills_scanned_Oct2020_byTier <-  num_bills_scanned_Oct2020_byTier %>%
  filter(scanCreatedMonth %in% c(10), scanCreatedYear %in% c(2020), !is.na(image)) %>%
  group_by(tierId) %>%
  summarise(numBillsScannedIn_Oct2020 = length(image))

# Scan Amount (billTotal) Sep 2020------------------------------------------------------

# selecting relevant columns
scan_amount_bill_total_Sep2020_byTier <- customer_user_scans_join_Q7 %>% 
  select(customerId, tierId, scanCreatedMonth, scanCreatedYear, billTotal)

# removing duplicates  
scan_amount_bill_total_Sep2020_byTier <- scan_amount_bill_total_Sep2020_byTier[!duplicated(scan_amount_bill_total_Sep2020_byTier), ]

# Scan Amount (billTotal) Sep 2020 summary table
scan_amount_bill_total_Sep2020_byTier <- 
  scan_amount_bill_total_Sep2020_byTier %>%
  filter(scanCreatedMonth %in% c(9), scanCreatedYear %in% c(2020)) %>%
  group_by(tierId) %>%
  summarise(scanAmountBillTotal_Sep2020 = sum(billTotal, na.rm = TRUE))

# adding a row for tier-5 and filling it with NA as there is no data in tier-5
scan_amount_bill_total_Sep2020_byTier <- dplyr::add_row(
  scan_amount_bill_total_Sep2020_byTier, tierId = 5, 
  scanAmountBillTotal_Sep2020 = NA
)

# Scan Amount (billTotal) October 2020--------------------------------------------

# selecting relevant columns
scan_amount_bill_total_Oct2020_byTier <- customer_user_scans_join_Q7 %>% 
  select(customerId, tierId, scanCreatedMonth, scanCreatedYear, billTotal)

# removing duplicates  
scan_amount_bill_total_Oct2020_byTier <- scan_amount_bill_total_Oct2020_byTier[!duplicated(scan_amount_bill_total_Oct2020_byTier), ]

# Scan Amount (billTotal) October 2020 summary table
scan_amount_bill_total_Oct2020_byTier <- 
  scan_amount_bill_total_Oct2020_byTier %>%
  filter(scanCreatedMonth %in% c(10), scanCreatedYear %in% c(2020)) %>%
  group_by(tierId) %>%
  summarise(scanAmountBillTotal_Oct2020 = sum(billTotal, na.rm = TRUE))

# Coupon Unlocks in September 2020-----------------------------------------------------

# selecting relevant columns
coupon_unlocks_sep2020_byTier <- customer_user_scans_join_Q7_join_coupTransRawUniq %>%
  select(customerId, tierId, scanCreatedMonth, scanCreatedYear, couponId, 
         couponUnlockDate) 

# removing duplicates 
coupon_unlocks_sep2020_byTier <- coupon_unlocks_sep2020_byTier[!duplicated(coupon_unlocks_sep2020_byTier), ]

# Coupon Unlocks in September 2020 summary table
coupon_unlocks_sep2020_byTier <-  coupon_unlocks_sep2020_byTier  %>%
  filter(scanCreatedMonth %in% c(9), scanCreatedYear %in% c(2020)) %>%
  group_by(tierId) %>%
  summarise(couponUnlocks_Sep2020 = sum(!is.na(couponUnlockDate)))

# adding a row for tier-5 and filling it with NA as there is no data in tier-5
coupon_unlocks_sep2020_byTier <- dplyr::add_row(coupon_unlocks_sep2020_byTier, tierId = 5, couponUnlocks_Sep2020 = NA)


# Coupon Unlocks in October 2020-----------------------------------------------------------

# selecting relevant columns
coupon_unlocks_Oct2020_byTier <- customer_user_scans_join_Q7_join_coupTransRawUniq %>%
  select(customerId, tierId, scanCreatedMonth, scanCreatedYear, couponId, 
         couponUnlockDate) 

# removing duplicate rows
coupon_unlocks_Oct2020_byTier <- coupon_unlocks_Oct2020_byTier[!duplicated(coupon_unlocks_Oct2020_byTier), ]

# Coupon Unlocks in October 2020 summary table
coupon_unlocks_Oct2020_byTier <-  coupon_unlocks_Oct2020_byTier %>%
  filter(scanCreatedMonth %in% c(10), scanCreatedYear %in% c(2020)) %>%
  group_by(tierId) %>%
  summarise(couponUnlocks_Oct2020 = sum(!is.na(couponUnlockDate)))

# All sub-parts of table created. Now, joining all the sub-parts of the table into a single dataset, in a format as asked in Q7 Part 1---------------------

monthOnMonthCompTableQ7P1 <- left_join(left_join(left_join(left_join(left_join(left_join(left_join(uniq_users_byTier_scanned_Sep2020, 
          uniq_users_byTier_scanned_Oct2020, by = "tierId"),
          num_bills_scanned_Sep2020_byTier, by = "tierId"), 
          num_bills_scanned_Oct2020_byTier, by = "tierId"), 
          scan_amount_bill_total_Sep2020_byTier, by = "tierId"), 
          scan_amount_bill_total_Oct2020_byTier, by = "tierId"), 
          coupon_unlocks_sep2020_byTier, by = "tierId"), 
          coupon_unlocks_Oct2020_byTier, by = "tierId")

```

&nbsp;

#### Important Note for interpreting the above code chunk: 

* There is a "createdAt" column both in the customer_user_raw dataset and customer_scans_raw dataset. The name is the same, but they mean different things. In the customer_user_raw dataset, the "createdAt" column refers to the **date at which the customer signed up**. 

* In the customer_scans_raw dataset, the "createdAt" column refers to *the date at which the scanned bill was created*.  

* To avoid confusion, after joining the customer_user_raw and customer_scans_raw dataset, I removed one of the "createdAt" column (one that comes from the customer_user_raw dataset and refers to the date of sign up).

* So, the "createdAt" in the **customer_user_scans_join_Q7** dataset, corresponds to the "createdAt" column of the "customer_scans_raw" data. It should be interpreted as, it would have been interpreted in the scans dataset, i.e. it is the date at which the scan was created.

* I also join the above (**customer_user_scans_join_Q7**) dataset with the **coupon_transactions_raw_unique** dataset. In the resulting dataset, called: **customer_user_scans_join_Q7_join_coupTransRawUniq**,  again, the "createdAt" column should be interpreted as: the date at which the scan was created.

* The final table is generated by joining each subset table (8 subset tables in total). This is why we see a bunch a lot of left_joins in the end of the above code chunk.

* Also, please note that 5th tier was not present in any of the September, 2020 subset tables, so before joining the subset tables, I added an additional (5th) row at the end of the dataset for the 5th tier (with its value being NA) for all September 2020 subset tables. 

&nbsp;

#### **Answer: Q7(Part-1):** Below present is the month on month comparison table in the format as asked in Q7 Part-1 of the assignement.

&nbsp;

```{r Q7-answer-part1-table, echo=TRUE, message=FALSE, warning=FALSE}

knitr::kable(monthOnMonthCompTableQ7P1)

```

&nbsp;

#### Q7 Part-1 Graphs: Generating a few graphs to get insight into the month-on-month comparison table genrated above. After this I will answer Q7: parts 2 and 3.

```{r Q7-part1-graphs, echo=TRUE, message=FALSE, warning=FALSE}

# bringing the data into a tidy format to make plots with ggplot2
monthOnMonthCompTableQ7P1_tidyFormat <- pivot_longer(monthOnMonthCompTableQ7P1, cols = !tierId, names_to = c("trait", "monthYear"), names_pattern = "(.+)_(.+)" , values_to = "values")

# Graph 1: Comparing total unique users who scanned in Sep v/s Oct (2020)
monthOnMonthCompTableQ7P1_tidyFormat %>% 
  filter(trait == "uniqUsersWhoScannedIn") %>%
  ggplot(mapping = aes(x = tierId, y = values, fill = monthYear)) +
  geom_col(position = "dodge") + 
  scale_y_continuous(breaks = seq(0, 500, by = 50)) +
  ggtitle("Unique users who scanned in Sep 2020 and Oct 2020") +
  geom_text(mapping = aes(label = values), position=position_dodge(width=0.9), vjust=-0.25) +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme_minimal()


# Graph 2: Comparing number of bills scanned in Sep v/s Oct (2020)
monthOnMonthCompTableQ7P1_tidyFormat %>% 
  filter(trait == "numBillsScannedIn") %>%
  ggplot(mapping = aes(x = tierId, y = values, fill = monthYear)) +
  geom_col(position = "dodge") + 
  ggtitle("Number of bills scanned in Sep 2020 and Oct 2020") +
  geom_text(mapping = aes(label = values), position=position_dodge(width=0.9), vjust=-0.25) +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme_minimal()


# Graph 3: Comparing: Scanned amount bill total in Sep v/s Oct 2020

monthOnMonthCompTableQ7P1_tidyFormat %>% 
  filter(trait == "scanAmountBillTotal") %>%
  ggplot(mapping = aes(x = tierId, y = values, fill = monthYear)) +
  geom_col(position = "dodge") + 
  ggtitle("Scanned amount bill total in Sep 2020 and Oct (2020)") +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme_minimal()


# Graph 4: Comparing Coupon Unlocks in Sep v/s Oct (2020)

monthOnMonthCompTableQ7P1_tidyFormat %>% 
  filter(trait == "couponUnlocks") %>%
  ggplot(mapping = aes(x = tierId, y = values, fill = monthYear)) +
  geom_col(position = "dodge") + 
  ggtitle("Coupon Unlocks in Sep 2020 and Oct (2020)") +
  geom_text(mapping = aes(label = values), position=position_dodge(width=0.9), vjust=-0.25) +
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme_minimal()

# Graph 5: A facetted bar plot to see all of the above in one graph (but y axis will be in log10 scale, as values for each group differ a lot)

monthOnMonthCompTableQ7P1_tidyFormat %>%
  ggplot(mapping = aes(x = tierId, y = values, fill = monthYear)) +
  geom_col(position = "dodge") + 
  scale_y_log10()+
  facet_wrap(~ trait) +
  ggtitle("Above 4 graphs in one plot with y axis in log10 scale")

```

&nbsp;

#### Note: In the final graph above with title **Above 4 graphs in one plot with y axis in log10 scale**, the y axis is in **log10** scale. For the 4 groups in the plot, range of values differs by a lot, hence y axis is log scaled, so as to display all 4 groups together in one single plot.

&nbsp;

<hr>

#### **Q7(Part-2):** Analyse the change in September Vs October and highlight/mention the highest changes for each tier

&nbsp;

```{r Q7-part2-answer, echo=TRUE, message=FALSE, warning=FALSE}

# adding 4 (difference columns) to monthOnMonthTableQ7P1 and creating a new dataset
# with only those columns and the tierId

monthOnMonthDifferenceCompQ7Part2 <-  monthOnMonthCompTableQ7P1 %>%
  mutate(diff_unq_users_scan_oct2020_sep2020 = (uniqUsersWhoScannedIn_Oct2020 - uniqUsersWhoScannedIn_Sep2020), 
         diff_num_bills_scanned_oct2020_sep2020 = 
           (numBillsScannedIn_Oct2020 - numBillsScannedIn_Sep2020), 
         diff_scan_amt_billTotal_oct2020_sep2020 = 
           (scanAmountBillTotal_Oct2020 - scanAmountBillTotal_Sep2020), 
         diff_couponUnlocks_oct2020_sep2020 = 
           (couponUnlocks_Oct2020 - couponUnlocks_Sep2020)) %>%
  select("tierId", starts_with("diff"))

monthOnMonthDifferenceCompQ7Part2

```

&nbsp;

#### **Answer: Q7(Part-2): This also contains  many observations that will count towards the answer of Q7(Part-3).** 

* In addition to the above graphs, below present is a  table that summarizes the same information (as in the above graphs), but in form of differences (October 2020 minus September 2020) by tierId. For example: **diff_scan_amt_billTotal_oct2020_sep2020** column contains the following information (for each tier): change(increase is +, decrease is -) in billTotal Amount from Sep 2020 to Oct 2020. 

* **The highest changes for each tier are as follows**:
  
  * First, note that because there is no data available for tier-5 in Sep 2020, we can not comment on how their metrics changed from september to october. Also, this is true in general for the entire dataset, as only 3 rows of data for tier-5 are present. So, when comparing changes (in various attributes of interest) from September 2020 to October 2020, we will focus on tier 1 to 4.
  
  * **[Ref table above and also the plot above named: Unique users who scanned in Sep 2020 and Oct 2020]**: The number of unique users who scanned dropped drastically (-43, a 22% decline from 191) for *tier-1* (from Sep2020 to Oct 2020) relative to the other tiers, which saw small gains (from Sep2020 to Oct2020) in the number of unique users who scanned.
  
  * **[Refer Table above and also the plot above named: Number of bill scanned in Sep 2020 and Oct 2020]**: The total number of bills scanned increased 20 fold (2000%, i.e from 1 to 21) for Tier-4 from September 2020 to October 2020. This was the biggest change in the total number of bills scanned for any given tier. Tier 3 also saw a 51% increase in total number of bills scanned (from 190 in sep 2020 to 287 in occt 2020). For the rest (tier 1 and 2), both saw a decline in the total number of bills scanned, with tier-1(-23%, from 339 to 257) declining almost 3 times more than tier-2(-9% from 935 to 850). 
  
  * **[Refer table above and also the plot above named: Scanned amount in bill total in Sep 2020 and Oct 2020]**: Scanned amount bill total increased (from Sep2020 to Oct2020) the most for Tier-3. This is consistent with point above in which we saw a 51% increase in the number of bills scanned. As, the number of bills scanned increases, so will the scanned amount of the bill. Similarly, as expected the percentage decline in scanned amount bill total for tier-1 is much more (-66%, a decline of ~ -2 Lacs from initial 6 lacs) than tier-2 (-4% ~ -3 lacs, from an intial of 65.5 lacs). Also, as we saw in the above point a 2000% increase in the total number of bills scanned for tier-4 (from sep 2020 to Oct 2020), here similarly we find that the increase in the scanned amount of bill total for tier-4 is a 218 fold increase, from a mere 275 Rs to massive 60K!.
  
  * **[Refer the table above and also the plot above named: Coupons unlocked in Sep 2020 and October 2020]**: For every tier (except tier-4, for which there was a marginal increase of 2 coupons), the coupon unlocks declined from Sep-2020 to October-2020. The decline in the number of coupons in tier-1 was 3 times (-30%, from 216 to 151) compared to tier-1 and tier-2 (both had a decline of 10%).  
   
&nbsp;

<hr>

#### **Answer: Q7(Part-3): Many of the above observations count towards the answer for Q7(Part-3). I will present a few more observations and insights below:**

* Tier-1 saw decline in all the places, given a 22% decline (from sep2020 to oct2020) in its unique users who scanned, there was a decline in all other variables too. For example, the *number of bills scanned* (declined by 23%) and scanned amount in bill total (declined by 66%) is expected as the number of unique users dropped from sep2020 to oct2020. Also, there was a 30 percent decline in coupons unlocked for tier-1, which makes sense as its unique users dropped significantly.

* For tier-2 even though, it saw a increase in the total number of unique users who scanned, the total number of bills scanned and the scanned amount in bill total both suffered a decline. This may be explained by the fact that the increase in the unique users who scanned was only by ~ 3% (from 341 to 351). So, even if assume that these additional 3% did scan, it is quite possible that this is easily offset by the rest of the tier spending/scanning a little less.

* As we noted in Q7 (Part-2), tier-3 saw a signficant increase in the number of bills scanned (and by effect the scanned Amount in Bill total) from September 2020 to October 2020. This increase is in part attributable to a 38% (from 42 to 58) in the number of unique users who scanned in tier-3.

* Also, for tier-4 we see that there was an increase of only 1 unique user who scanned (from Sep2020 to Oct2020), but the number of bills scanned increased by 20 fold (from 1 to 21). As a consequence of this the scanned amount in bill total for tier-4  users saw a 218 fold increase, from a mere Rs 275, to Rs 60,000. Although, remember that because there are only 2 unique users in this group. All of this increased scanning of bills can be largely attributed to the user who joined the list (sometime between sep2020 to oct2020) of unique users who scanned.

* We see a general trend in which tier-3 and above are scanning more and more, but this whole scanning exercise is significantly reduced for tier 1 and tier-2. This may point that tier-1 and tier-2 are not going out much, to buy things. They reside in high population centers, with access to online services for everything (especially in the times of the Coronavirus pandemic, Oct 2020 was a time at which Pandemic was at its peak). The decline in scanning is probably matched by a rise in online shopping, that does not require any buying or scanning.

* But, at the same time, we see a rise in scanning for Tier-3 and Tier-4 users who belong to the suburbs or areas with low population, lack of access to internet, online services, home-delivery, lack of knowledge of using online services etc. Also, it is very likely that these people have much less resources compared to the Tier-1 and Tier-2 users, who can afford to buy much more from the safety of their homes. 

* It is much more likely, that if tier-3 or tier-4 users need to buy something, they need to go out to the store to do so. This may be due to the fact that they do not have access to smartphones/computers. Or, even if they do, they may not know how to use the various apps on their phones that allow for online shopping. Even, if they do know how to do so, they may not want to pay extra for those services, and may prefer local goods, that may be much cheaper.

&nbsp; 

<hr>
* **End of File:** For any questions, please feel free to call me anytime at: 8800592799.
<hr>





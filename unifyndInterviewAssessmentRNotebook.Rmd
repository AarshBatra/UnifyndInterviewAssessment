---
title: "Unifynd Interview Assessment (Data Analytics) R Notebook"
output:
  html_document:
    df_print: paged
---

&nbsp;

&nbsp;

<hr>

&nbsp;

## File Structure

* To ensure that best practices are followed  (by design), this entire task is executed as a R package. 

* This is why I have shared the entire package directory with you as my submission for this data task.

* In the directory, there is a .RProj (R project file). If you open it in R Studio (R Studio is required for running this), you will have all the relevant environment needed for you to run this R Markdown Notebook (named: unifyndInterviewAssessmentRNotebook.Rmd). Note that this file has a .Rmd extension.

* This R notebook contains all the code, output and answers for all of the 7 questions(and its sub-parts) in the task. This R Notebook (.Rmd file) is present in the root of the package directory. 

* Also all the helper (.R) scripts, other than this .Rmd file, can be found in the **R** sub-directory.

* Just make sure that you have all the R packages (mentioned in the "load_libraries" chunk in this R Notebook below) installed on your system. 

* Also, make sure that your paths are set as per your system. I have used relative paths in the code, but still it is good to have this as a Sanity check before running the code.

* Once you have followed all of the above steps, please continue reading below on how to use this R Notebook.

&nbsp;

<hr>

## How to use this R Markdown notebook? 

* You can preview this notebook using the **Preview** button, which will show you rendered HTML copy of the contents of the editor. 

* The other option is to knit this notebook into a neat PDF, which you can do using the **Knit** button.
 
* Unlike **Knit**, **Preview** does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed. So, when you use **Preview**, please make sure that you have once run all the chunks of code in the editor. Once you run all chunks and then preview, the resulting html output will show all code and all output (plots, tables, etc).

* This notebook contains all code, output and answers, for all of the 7 Questions (and all its sub-parts). By that I mean, it also contain answers to theory questions (ones in which I am asked about my observations and insights, e.g. Q7:part-3).

* I have also attached a complete pre-knitted PDF (with all code, output, answers) in my submission files (along side this .Rmd file).

* Feel free to reach out to me at **aarshbatra.in@gmail.com**/8800592799 if you have any questions or run into any problems. I will quickly troubleshoot it for you.

&nbsp;

<hr>

## Initial Setup

```{r metadata, echo=TRUE, message=FALSE, warning=FALSE}

# metadata---------------------------------------------------------------------
# author: Aarsh Batra
# Start Date: October 07, 2021
# R version: 4.1.1 (2021-08-10)
# nickname: Kick Things
# Platform: x86_64-w64-mingw32 
# arch: x86_64
# Running under: Windows 10 x64 (build 18363)
# R Studio version info: 2021.09.0+351 "Ghost Orchid"
# e-mail: aarshbatra.in@gmail.com

```


```{r load-libraries, message=FALSE, warning=FALSE, include=FALSE}

# load libraries---------------------------------------------------------------

library(tidyverse)
library(knitr)
library(devtools)
library(stringr)
library(tidyr)
library(dplyr)
library(skimr)
library(magrittr)
library(data.table)
library(lubridate)
library(roxygen2)
library(testthat)
library(ggplot2)
library(readr)
library(readxl)
```

```{r load-entire-package, echo=TRUE, message=FALSE, warning=FALSE}

# loading the entire package--------------------------------------------------

devtools::load_all()

```


```{r read-raw-datasets, echo=TRUE, message=FALSE, warning=FALSE}

# read in raw .xlsx datasets into R--------------------------------------------

coupon_transactions_raw <- read_raw_xlsx_data("couponTransactions.xlsx")
 
 customer_scans_raw <- read_raw_xlsx_data("customerScans.xlsx")
                                          
 customer_user_raw <- read_raw_xlsx_data("customerUser.xlsx")
```

&nbsp;

<hr>

## Exploratory Data Analysis

* First, I will explore the dataset after which I will proceed to
answering the questions. Everything inside the below chunk of code is for exploration only. I have commented out most of the exploratory code, if you'd like to see what it does, you may uncomment it. None of the variable from the below chunk exploratory code are used after this chunk of code. Still, I have included some of the main exploratory code output below. 

&nbsp;

```{r exploratory-data-analysis-question-wise}

# exploring coupon_transaction_raw dataset-------------------------------------

# View(coupon_transactions_raw)

# getting a basic summary
skimr::skim(coupon_transactions_raw)

# # number of unique customers
#   length(unique(coupon_transactions_raw$customerId)) # 14979
# 
# # number of unique couponUnlock dates
#   length(unique(coupon_transactions_raw$couponUnlockDate)) # 291
# 
# # number of unique couponId's
# length(unique(coupon_transactions_raw$couponId)) # 328


# exploring customer_scans_raw dataset-----------------------------------------

# View(customer_scans_raw)

# skim customer_scans_raw dataset
skimr::skim(customer_scans_raw)

# # max amount for billTotal column
# max(customer_scans_raw$billTotal) # why is this too big? look into this.
# 
# # number of unique customers
# length(unique(customer_scans_raw$customerId))
# 
# # number of unique scan log ids
# length(unique(customer_scans_raw$scanlogId))
# 
# # number of unique stores
# length(unique(customer_scans_raw$storeName))
# 
# # store with the maximum bill total
# customer_scans_raw %>% 
#   filter(billTotal == max(billTotal)) %>%
#   select(storeName)
# 

# exploring customer_user_raw data---------------------------------------------

# View(customer_user_raw)

# skim customer_user_raw dataset
skimr::skim(customer_user_raw)

# # number of unique customers
# unique(length(customer_user_raw$customerId))
# 
# # number of unique tierId's 
# length(unique(customer_user_raw$tierId))
# 

# wrapping up exploratory data analysis with a few more queries-----------------
colnames_for_datasets_list <- list(coup_trans_col = colnames
                                   (coupon_transactions_raw),
                                cust_scans_col = colnames(customer_scans_raw), 
                              cust_user_col = colnames(customer_user_raw))

# one common column between coupon_transactions_raw and customer_scans_raw
sum(colnames_for_datasets_list[[2]] %in% 
      colnames_for_datasets_list[[1]])  # customerId

# two common columns between customer_scans_raw and customer_user_raw
sum(colnames_for_datasets_list[[3]] %in% 
      colnames_for_datasets_list[[2]]) # customerId, createdAt

# one common column between customer_user_raw and coupon_transactions_raw
sum(colnames_for_datasets_list[[3]] %in% 
      colnames_for_datasets_list[[1]]) # customerId
```
&nbsp;

<hr>

## Pre-processing data

* Given the exploratory data analysis above, we find that the datasets are in a
tidy format and are relatively clean so no pre-processing is necessary.

&nbsp;

<hr>

## Let's get to the answers:

&nbsp;

### Code and answer for Q1

#### **Question 1**: How many Users have logged in after 1st September 2020 till date? How many of those have Signed up in September 2019?

&nbsp;

#### Code

&nbsp;

```{r Q1-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# number of users who have logged in after 1st September 2021, till date

customer_user_raw_Q1_subset <- customer_user_raw %>%
  select(customerId, createdAt, lastLogin, tierId) %>%
  filter(lastLogin > lubridate::as_datetime("2020-09-01")) %>%
  distinct()
 
customer_user_raw_Q1_subset

 num_users_log_in_after_sep2021 <- customer_user_raw_Q1_subset %>%
   nrow()                                
 
 num_users_log_in_after_sep2021 # answer to Q1Part-1 = 10,323 users


# Of the above 10,323 users, how many signed up in September, 2019.

 num_user_logInAfterSep2021_signedUpInSep2019 <- customer_user_raw_Q1_subset %>%
  dplyr::filter(lubridate::month(createdAt) == 09, lubridate::year(createdAt) == 2019) %>%
   nrow()

 num_user_logInAfterSep2021_signedUpInSep2019 # answer to Q2Part-2 = 209 users

```

&nbsp;

#### **Answer 1 (part 1)**: `r num_users_log_in_after_sep2021` users have logged in after 1st September 2021, till date.

&nbsp;

#### **Answer 1 (part 2)**: Of the `r num_users_log_in_after_sep2021` users from part 1 above, `r num_user_logInAfterSep2021_signedUpInSep2019` users have signed up in September 2019.

&nbsp;

* Please Note: In the absence of a data dictionary describing what each column 
means, I have made the following assumptions about the columns in the 
**customer_users_raw** dataset: I have assumed that  the **createdAt** column 
in the corresponds to the sign_up date column, and the **lastLogin** corresponds
to the login column. This might seem obvious, but it is still worth mentioning.

&nbsp;

<hr>

### Code and answer for Q2

&nbsp;

#### **Question 2:** How many users have earned points more than 2000?

&nbsp;

```{r Q2-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# sanity check
sum(is.na(customer_user_raw$earnedPoints))

# Number of users who have earnedPoints more than 2000
num_users_earned_points_more_than_2000 <- customer_user_raw %>%
  dplyr::filter(earnedPoints > 2000) %>% 
  distinct() %>%
  nrow()                          

 num_users_earned_points_more_than_2000            # answer to Q2 = 1261

```
&nbsp;

#### **Answer 2:** `r num_users_earned_points_more_than_2000` users have earned points more than 2000.

&nbsp;

<hr>

### Code and answer for Q3

&nbsp;

#### **Question 3: ** From which stores has customer id ‘83’ scanned bills in February 2020?

&nbsp;

```{r Q3-answer-code, echo=TRUE, message=FALSE, warning=FALSE}
customer_scans_raw_Q3_subset <- customer_scans_raw %>%
  filter(customerId == 83, lubridate::month(createdAt) == 02, 
         lubridate::year(createdAt) == 2020) %>%
  dplyr::select(customerId, storeName, createdAt, image) %>%
  dplyr::group_by(storeName) %>%
  dplyr::summarise(numBillsScanned = length(unique(image))) %>%
  dplyr::mutate(customerId = 83, month = "February, 2020") %>%
  dplyr::select(customerId, everything())

```

&nbsp;

#### **Answer to Q3:** Below is a table, which lists the stores from which customer id "83" scanned bills in February, 2020. It also lists the total number of unique bills scanned by customer Id "83" for each store. This information is useful in case more than one bill is scanned per store. 

&nbsp;

```{r Q3-answer-table, echo=TRUE, message=FALSE, warning=FALSE}
knitr::kable(customer_scans_raw_Q3_subset)
```

&nbsp;

* Please Note: In the absence of a data dictionary describing what each column 
means, I have made the following assumptions about the columns in the 
**customer_scans_raw** dataset: I have assumed that  the **createdAt** column 
in this dataset corresponds to the date at which the scan was created, and the 
**billDate** column corresponds to date on which the bill was generated. 
Also, there is a date within the image file names, because we do not know, what
that date represents, I haven't extracted or used it.

&nbsp;

<hr>

### Code and answer for Q4 

&nbsp;

#### **Question 4**: How many unique users unlocked coupons on 10th September 2020?

&nbsp;

```{r Q4-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# creating a coupon_transactions_raw with duplicate rows removed
coupon_transactions_raw_unique <- coupon_transactions_raw[!duplicated(coupon_transactions_raw), ]

coupon_transactions_raw_Q4_subset <- coupon_transactions_raw_unique %>%
  filter(couponUnlockDate == lubridate::as_datetime("2020-09-10")) %>%
  group_by(customerId) %>%
  summarise(numUniqueCouponsUnlocked = length(unique(couponId))) %>%
  mutate(dateOnWhichCouponUnlocked = "September 10, 2020")

num_unique_users_unlocked_coupons_on_Sep102020 <- 
  nrow(coupon_transactions_raw_Q4_subset)     # answer to Q4 = 34 unique users.


```

&nbsp;

#### **Answer to Q4:** `r num_unique_users_unlocked_coupons_on_Sep102020` unique users unlocked coupons on September 10, 2021. Below presented is a table that lists these unique users and also shows the number of unique coupons unlocked by each one of them on September 10, 2021.

&nbsp;

```{r Q4-answer-table, echo=TRUE, message=FALSE, warning=FALSE}

knitr::kable(coupon_transactions_raw_Q4_subset)

```

&nbsp;

<hr>

### Code and answer for Q5

&nbsp;

#### **Question 5: ** Create a pivot table as mentioned in the question description in the [Question PDF file](https://github.com/AarshBatra/UnifyndInterviewAssessment/blob/master/Interview%20Assignment%20_%20Data%20Analytics.pdf)

&nbsp;

```{r Q5-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# sanity checks (for understanding purposes only, these sanity check variables
# are not used in code)
foo <- dplyr::left_join(x = coupon_transactions_raw, y = customer_user_raw, by = c("customerId" = "customerId"))
sum(coupon_transactions_raw$customerId %in% customer_user_raw$customerId)
sum(!(customer_user_raw$customerId %in% coupon_transactions_raw$customerId))        

foo1Ind <- customer_user_raw$customerId %in% coupon_transactions_raw$customerId
foo1Val <- customer_user_raw$customerId[foo1Ind]
nrow(filter(coupon_transactions_raw, customerId %in% foo1Val))


# First: left_join the "customer_user_raw" and "coupon_transaction_raw_unique" data by the "customerId" column as a KEY

customer_user_coupon_join_Q5 <- dplyr::left_join(x = customer_user_raw, y = coupon_transactions_raw_unique, by = "customerId")

# removing duplicate rows
customer_user_coupon_join_Q5_unique <-  customer_user_coupon_join_Q5[!duplicated(customer_user_coupon_join_Q5), ]

# create Pivot table, by using tierId  as the "group" column
pivot_table_by_tier_Q5 <- customer_user_coupon_join_Q5_unique %>%
  dplyr::group_by(tierId) %>%
  dplyr::summarise(numUniqueUsersInEachTier = length(unique(customerId)),
            totalCouponsUnlocked = sum(!is.na(couponUnlockDate)),
            averageEarnedPoints = mean(earnedPoints, na.rm = TRUE), 
            averageBurnedPoints = mean(burnedPoints, na.rm = TRUE))


```

&nbsp;

#### **Answer 5:** Pivot Table for Q5

&nbsp;

```{r Q5-answer-pivot-table }
knitr::kable(pivot_table_by_tier_Q5)
```

&nbsp;

<hr>

### Code and answer for Q6

#### **Question 6:** Create a cohort of users with the following conditions (Scan Count > 4 && Coupon Transaction Count > 2) and answer the following questions:

  * 1. What’s the tier distribution of these users?
  * 2. What’s the gender distribution of these users?
  * 3. Which 5 stores have these users scanned the most from?
  * 4. Which source has the most users coming from in this cohort?
  * 5. Observe the behaviour of this cohort and write your observations and 
       insights.

&nbsp;

#### Getting the number and id's of customers that belong to the cohort whose scanCount > 4 and couponTransactionCount > 2

&nbsp;
       
```{r Q6-answer-get-cohort, echo=TRUE, message=FALSE, warning=FALSE}

# get a vector of customerId's that satisfy the cohort conditions--------------
  
# customers with scan count > 4
customer_scans_raw_Q6_subset <- customer_scans_raw %>%
group_by(customerId) %>%
summarise(scanCount = sum(!is.na(unique(scanlogId)))) %>%
filter(scanCount > 4) 

# removing duplicates
customer_scans_raw_Q6_subset_unique <- customer_scans_raw_Q6_subset[
  !duplicated(customer_scans_raw_Q6_subset), ]

# For the customers whose scan count is greater than 4, select those whose
# coupon transaction count > 2.

# creating a subset of data that corresponds to those customers whose 
# scan count > 4
coupon_transactions_raw_Q6_subset <- coupon_transactions_raw %>%
  filter(customerId %in% customer_scans_raw_Q6_subset_unique$customerId) 

# removing any duplicate rows
coupon_transactions_raw_Q6_subset_unique <-  coupon_transactions_raw_Q6_subset[!duplicated
            (coupon_transactions_raw_Q6_subset), ]

# dataset containing customers whose "scanCount" > 4 and couponTransactionCount
# is > 2
coupon_transactions_raw_Q6_subset_unique_finCohort <- coupon_transactions_raw_Q6_subset_unique %>% 
  group_by(customerId) %>%
  summarise(couponTransactionCount = sum(!is.na(couponUnlockDate))) %>%
  filter(couponTransactionCount > 2)

# putting the cohort customers (that satisfy the cohort definition) into a 
# vector

cohort_customers <- coupon_transactions_raw_Q6_subset_unique_finCohort$customerId


```

&nbsp;

#### Given the above calculations, the cohort whose scanCount > 4 and couponTransactionCount > 2, contain a total of `r length(cohort_customers)` customers.These customers are stored in the vector named **cohort_customers**. Now, I will use this information to answer parts 1 to 5 of Q6. For each part, I will first present the code and then its answer (figure/table/etc).

&nbsp;

<hr>

#### **Code and Answer to Question 6: Part-1**

&nbsp;

#### **Q6(Part-1):** What is the tier distribution of Cohort users?

&nbsp;

```{r Q6-answer-part1, echo=TRUE, message=FALSE, warning=FALSE}

# making sure that we are only using users that satisfy cohort definition
tier_dist_cohort_users <- customer_user_raw %>%
  filter(customerId %in% cohort_customers) 

# removing duplicate rows (if any)
tier_dist_cohort_users <- tier_dist_cohort_users[!duplicated(tier_dist_cohort_users), ]

# grouping and summarising by tierId
tier_dist_cohort_users <- tier_dist_cohort_users %>%
  group_by(tierId) %>%
  summarise(countOfUsers = n()) %>%
  mutate(percentOfUsers = (countOfUsers/sum(countOfUsers, na.rm = TRUE))*100)

# plot: tier distribution of cohort users  
tier_dist_cohort_users_plot <-  tier_dist_cohort_users %>%
  ggplot(mapping = aes(x = tierId, y = countOfUsers)) +
  geom_col(width = 0.5) +
  scale_y_continuous(breaks = seq(0, 500, by = 30)) +
  geom_text(mapping = aes(label = countOfUsers), position=position_dodge(width=0.9), vjust=-0.25) + ggtitle("Tier distribution of Cohort users") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

&nbsp;

#### **Answer: Q6(Part-1):** Below is a table and a bar graph of of the tier distribution of cohort users

&nbsp;

```{r Q6-answer-part1-tabGraph, echo=TRUE, message=FALSE, warning=FALSE}

# plot: tier distribution of cohort users
tier_dist_cohort_users_plot

# Table: tier distribution of cohort users
knitr::kable(tier_dist_cohort_users)

```

&nbsp;

<hr>

#### **Q6(Part-2):** What the gender distribution of Cohort users?

&nbsp;

```{r Q6-answer-part2, echo=TRUE, message=FALSE, warning=FALSE}

# making sure that we are only using users that satisfy cohort definition
gender_dist_cohort_users <- customer_user_raw %>%
  filter(customerId %in% cohort_customers) 

# removing duplicate rows (if any)
gender_dist_cohort_users <- gender_dist_cohort_users[!duplicated(gender_dist_cohort_users), ]

# grouping and summarising by gender
gender_dist_cohort_users <- gender_dist_cohort_users %>%
  group_by(gender) %>%
  summarise(countOfUsers = n()) %>%
  mutate(percentOfUsers = (countOfUsers/sum(countOfUsers, na.rm = TRUE))*100)

# plot: gender distribution of cohort users
gender_dist_cohort_users_plot <-  gender_dist_cohort_users %>%
  ggplot(mapping = aes(x = gender, y = countOfUsers)) +
  geom_col(width = 0.5) +
  scale_y_continuous(breaks = seq(0, 500, by = 30)) +
  geom_text(mapping = aes(label = countOfUsers), position=position_dodge(width=0.9), vjust=-0.25) + ggtitle("Gender distribution of Cohort users") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))


```

&nbsp;

<hr>

#### **Answer: Q6(Part-2):** Below is a table and a bar graph of of the gender distribution of cohort users.

* Please note: In this cohort, of the total `r length(cohort_customers)` there are `r nrow(customer_user_raw %>% filter(customerId %in% cohort_customers, gender == "NULL"))` customers whose value for gender column is "NULL" in the dataset. Also, there are `r nrow(customer_user_raw %>% filter(customerId %in% cohort_customers, is.na(gender)))` customers whose value for the gender column is "NA". In the gender distribution below (both in table and in graph), I have kept them, instead of filtering them out, as it is good to have a visual representation 
of these missing values.

&nbsp;

```{r Q6-answer-part2-tabGraph, echo=TRUE, message=FALSE, warning=FALSE}

# plot: gender distribution of cohort users
gender_dist_cohort_users_plot

# table: gender distribution of cohort users
knitr::kable(gender_dist_cohort_users)

```

&nbsp;

<hr>

#### **Q6(Part-3):** Which 5 stores have these users scanned the most from?

&nbsp;

```{r Q6-answer-part3, echo=TRUE, message=FALSE, warning=FALSE}

# making sure that we are only using users that satisfy cohort definition
cohort_users_5_stores_scanned_most_from <- customer_scans_raw %>% 
  filter(customerId %in% cohort_customers) 

# removing duplicate rows (if any)
cohort_users_5_stores_scanned_most_from <- cohort_users_5_stores_scanned_most_from[!duplicated(cohort_users_5_stores_scanned_most_from), ]

# grouping and summarising by Store name
cohort_users_5_stores_scanned_most_from <- cohort_users_5_stores_scanned_most_from %>%
  group_by(storeName) %>%
  summarise(scansCount = n()) %>% 
  slice_max(scansCount, n = 5) %>%
  mutate(scansPercentage = (scansCount/sum(scansCount, na.rm = TRUE))*100)



# plot: 5 stores the user scanned the most from
cohort_stores_top5_scanned_most_plot <-  
  cohort_users_5_stores_scanned_most_from %>%
  dplyr::arrange(scansCount) %>%
  ggplot(mapping = aes(x = storeName, y = scansCount)) +
  geom_col(width = 0.5) +
  scale_y_continuous(breaks = seq(0, 1800, by = 100)) +
  geom_text(mapping = aes(label = scansCount), position=position_dodge(width=0.9), vjust=-0.25) + ggtitle("5 stores users scanned most from") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

&nbsp;

#### **Answer: Q6(Part-3):** Below is a table and a bar graph for the 5 stores from which the cohort users scanned the most.

&nbsp;

```{r Q6-answer-part3-tabGraph, echo=TRUE, message=FALSE, warning=FALSE}

# plot: 5 stores customers scanned most from
cohort_stores_top5_scanned_most_plot

# table: 5 stores customers scanned most from
knitr::kable(cohort_users_5_stores_scanned_most_from)


```

&nbsp;

<hr>

#### **Q6(Part-4):** Which source has the most users coming from in this cohort?

&nbsp;


```{r Q6-answer-part4, echo=TRUE, message=FALSE, warning=FALSE}

# making sure that we are only using users that satisfy cohort definition
cohort_source_users <- customer_user_raw %>% 
  filter(customerId %in% cohort_customers)

# removing duplicate rows (if any)
cohort_source_users <- cohort_source_users[!duplicated(cohort_source_users), ]

# grouping and summarizing by "source" column
cohort_source_users <- cohort_source_users %>%
  group_by(source) %>%
  summarise(userCount = n()) %>%
  mutate(userPercentage = (userCount/sum(userCount, na.rm = TRUE))*100)

# Answer table for Q6 Part 4: Which source has the most users coming from?
cohort_source_most_users_table <- cohort_source_users %>%
  slice_max(userCount, n = 5)

# plot: Top 5 sources from which most users are coming
cohort_source_most_users_table_plot <-  
  cohort_source_most_users_table %>%
  dplyr::arrange(userCount) %>%
  ggplot(mapping = aes(x = source, y = userCount)) +
  geom_col(width = 0.5) +
  scale_y_continuous(breaks = seq(0, 1800, by = 100)) +
  geom_text(mapping = aes(label = userCount), position=position_dodge(width=0.9), vjust=-0.25) + ggtitle("Top 5 sources from which most users are coming") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

&nbsp;

#### **Answer: Q6(Part-4):** 

* Below is a table and a bar graph for the top 5 sources from which most of the users are coming in this cohort. 

* The question asks to list the top source from which most users are coming. As is clear from the bar graph below, most of the source information is missing (NA, NULL).

* Instead of removing them from the plot, I have kept these intentionally as I always find it useful to have a visual representation of what is missing from the dataset. Otherwise, many times, it simply gets missed from analysis.

* But, if we ignore the `r filter(cohort_source_most_users_table, is.na(source))$userCount` NA values, and `r filter(cohort_source_most_users_table, source == "NULL")$userCount` NULL values, the source from which the highest number of users are coming is `r cohort_source_most_users_table$source[3]`, with total number of users = `r cohort_source_most_users_table$userCount[3]`.

* So, the answer for Question 6(part-4) is: `r cohort_source_most_users_table$source[3]` is the source from which `r cohort_source_most_users_table$userCount[3]` users are coming.

&nbsp;

```{r Q6-answer-part4-tabGraph, echo=TRUE, message=FALSE, warning=FALSE}

# plot: Top 5 sources from which most users are coming
cohort_source_most_users_table_plot

# table: Top 5 sources from which most users are coming
cohort_source_most_users_table
```

&nbsp;

<hr>

#### A few other graphs to help better understand Q6:

&nbsp;

```{r Q6-extra-graphs, echo=TRUE, message=FALSE, warning=FALSE}

foo_user_tmp <- customer_user_raw %>%
  filter(customerId %in% cohort_customers)

foo_scans_tmp <- customer_scans_raw %>%
  filter(customerId %in% cohort_customers,
         storeName %in% cohort_users_5_stores_scanned_most_from$storeName)


# gender distribution within tiers
foo_user_tmp %>% 
  ggplot(mapping = aes(x = tierId, fill = gender)) +
  geom_bar(position = "dodge") + 
  ggtitle("gender distribution within tiers")

# billTotal distribution for top 5 stores users scanned most from
foo_scans_tmp %>% 
  ggplot(mapping = aes(x = storeName, y = billTotal)) +
  scale_y_log10() +
  geom_boxplot() + 
  xlab("log10(billTotal)") +
  ggtitle("log10(billTotal) distribution for top 5 stores users scanned most from")

  
```


&nbsp;

<hr>

#### **Q6(Part-5):** Observe the behaviour of this cohort and write your observations and insights.

&nbsp;

#### **Answer: Q6(Part-5):** Observations and Insights:

* In this cohort, more than 75% of the total number of users live in tier-2 alone. 86% of the users live in tier-1 and tier-2 combined. 98% of the users live in tier-1, tier-2 and tier-3 combined. Almost no one lives in Tier-4 and Tier-5. This shows that this particular cohort mostly resides in Urban high population centers. **[Refer: Tier distribution of Cohort users plot]**.

* Around 70% of the users in this cohort are Males and 30% females. But, almost 15% of data on 'gender' is missing (either NA, or NULL). **[Refer: Gender distribution of cohort users plot]**.
  
  *The sex ratio for India according to [this article](https://www.census2011.co.in/sexratio.php) is 1.06 males for every 1 female. This means that for every 1000 females there are 1060 males. 
  
  * The sex ratio in our cohort (with missing gender data) is 2.47 males for 1 female, which would mean that for every 1000 females, there are 2,470 males. That does not seem right. Gender gap will probably decrease if missing data becomes available.
  
* Almost all of the missing data, comes from either tier-1, tier-2 or tier-3. This makes sense as that is where most of the users reside. **[Refer: Gender distribution within tiers plot]**

* Gender gap within tiers is similar to the gender gap in the  overall data. But, as mentioned earlier, this is probably because a lot of data on gender is missing. **[Refer: Gender distribution within tiers plot]**

* Users scanned the most from Big Bazaar. Of the total number of scans count in the top 5 stores (from which users scanned the most), more than half of those scans are for Big Bazaar. The next big chunk is taken by the Lifestyle store, followed by Luxe, Latt Liv and Miniso. **[Refer: 5 stores users scanned most from plot]**

* Big Bazaar and Lifestyle probably being the most pocket friendly, were the ones that users scanned the most. But, for more expensive (relatively) stores like Luxe, Miniso, Latt Liv we see lesser number of scans (compared to Big Bazaar). **[Ref: 5 stores users scanned most from plot]**

* The source from which most users are coming is NPBPROMO3, the next best top sources also are versions of this NPBPROMO class. This means that these are probably the best places for shop owners to invest their money in to attract customers.**[Refer: Top 5 sources from which most users are coming]**

* **[Refer: billTotal distribution for top 5 stores users scanned most from]**
 
  * We see that average values for billTotal for all stores is approximately the same. For big bazaar the average is the lowest, which is expected.
  
  * There is a high amount of variation in the distribution of billTotal for both Big Bazaar and Lifestyle. This is probably because of the variety of products they sell. That also explains the most number of bills being scanned in these stores, as they attract people from all tiers.
  
  * Their is very little amount of variation in the billTotal of Miniso store, which probably hints at the streamlined product lines that it has for people who can afford to spend more, probably mostly tier-1 and tier-2 people.
  
  * In all stores, except Luxe, there is small amount if variation around the average, or in other words, the Inter Quartile Range is small. This tells us that, except for Luxe (which has a large amount of variation in its billTotal), all other stores have billTotals that stay close to the average billTotal amount.


&nbsp;

<hr>

### Code and answer for Q7

#### **Question 7:** Month on Month comparison:

* 1) From the given tables derive this table(execute joins with other  tables if      required).
  
* 2) Analyse the change in September Vs October and highlight/mention the            highest changes for each tier
  
* 3) Observe the metrics and write your observations and insights

&nbsp;

#### **Code and Answer to Question 7: Part-1**

&nbsp;

&nbsp;

#### **Q7(Part-1):** From the given tables derive this table(execute joins with other tables if required)

#### Code

```{r Q7-answer-part1, echo=TRUE, message=FALSE, warning=FALSE}

# sanity checks
sum(customer_scans_raw$customerId %in%
  customer_user_raw$customerId) == length(customer_scans_raw$customerId)

sum(customer_user_raw$customerId %in%
  customer_scans_raw$customerId)

# performing a left-join and combining the "customer_user_raw" data with "customer_scans_raw data" 

customer_user_scans_join_Q7 <- dplyr::left_join(
  select(customer_user_raw, -createdAt), customer_scans_raw, by = "customerId")

# removing duplicate rows (if any) unlikely that we will see duplicate rows here as there are a lot of columns
customer_user_scans_join_Q7 <- customer_user_scans_join_Q7[!duplicated(customer_user_scans_join_Q7), ]

# adding 2 columns, a month and a year column to the customer_user_scans_join_Q7 dataset------------------------------------------------------------------------ 

# we will derive these column is derived from the "createdAt" column of the joined dataset. The "createdAt" column in the joined dataset, contains the date at which the scan was created.

# Note that, there was a "createdAt" column in the customer_user_raw dataset, # although the name is the same, that refers to the date at which the customer signed up. To avoid confusion, I removed that column, while joining rhe dataset. 
# So, the "createdAt" in the joined dataset, corresponds to the "createdAt" column of the "customer_scans_raw" data. It should be interpreted as, it would have been interpreted in the scans dataset, i.e. it is the date at which the scan was created.

# From this column, I will derive two new columns and add it to the joined data set before.

customer_user_scans_join_Q7 <- customer_user_scans_join_Q7 %>%
  mutate(scanCreatedMonth = lubridate::month(createdAt), 
         scanCreatedYear = lubridate::year(createdAt))

# left_join customer_user_scans_join_Q7 dataset with coupon_transactions_raw_unique



# Create parts of table separately and then bind them together-----------------

# Unique users (by TierId) who scanned in Sep 2020
uniq_users_byTier_scanned_Sep2020 <- customer_user_scans_join_Q7 %>% 
  filter(scanCreatedMonth %in% c(9), scanCreatedYear %in% c(2020), !is.na(createdAt)) %>%
  group_by(tierId) %>%
  summarise(uniqUsersWhoScannedInSep2020 = length(unique(customerId)))

# Unique users (by TierId) who scanned in Oct 2020
uniq_users_byTier_scanned_Oct2020 <- customer_user_scans_join_Q7 %>% 
  filter(scanCreatedMonth %in% c(10), scanCreatedYear %in% c(2020), !is.na(createdAt)) %>%
  group_by(tierId) %>%
  summarise(uniqUsersWhoScannedInSep2020 = length(unique(customerId)))

# Number of bills scanned (Image) in Sep 2020
num_bills_scanned_Sep2020_byTier <- customer_user_scans_join_Q7 %>% 
  filter(scanCreatedMonth %in% c(9), scanCreatedYear %in% c(2020), !is.na(image)) %>%
  group_by(tierId) %>%
  summarise(numBillsScannedInSep2020 = length(image))

# Number of bills scanned (Image) in Oct 2020
num_bills_scanned_Oct2020_byTier <- customer_user_scans_join_Q7 %>% 
  filter(scanCreatedMonth %in% c(10), scanCreatedYear %in% c(2020), !is.na(image)) %>%
  group_by(tierId) %>%
  summarise(numBillsScannedInOct2020 = length(image))

# Scan Amount (billTotal) Sep 2020
scan_amount_bill_total_Sep2020_byTier <- customer_user_scans_join_Q7 %>% 
  filter(scanCreatedMonth %in% c(9), scanCreatedYear %in% c(2020)) %>%
  group_by(tierId) %>%
  summarise(scanAmountBillTotalSep2020 = sum(billTotal, na.rm = TRUE))

# Scan Amount (billTotal) October 2020
scan_amount_bill_total_Oct2020_byTier <- customer_user_scans_join_Q7 %>% 
  filter(scanCreatedMonth %in% c(10), scanCreatedYear %in% c(2020)) %>%
  group_by(tierId) %>%
  summarise(scanAmountBillTotalOct2020 = sum(billTotal, na.rm = TRUE))



```








---
title: "Unifynd Interview Assessment (Data Analytics) R Notebook"
output:
  html_document:
    df_print: paged
---

# File Structure 

* To ensure that best practices are followed  (by design), this entire task is executed as a R package. 

* This is why I have shared the entire package directory with you as my submission for this data task.

* In the directory, there is a .RProj (R project file). If you open it in R Studio (R Studio is required for running this), you will have all the relevant environment needed for you to run this R Markdown Notebook (named: unifyndInterviewAssessmentRNotebook.Rmd). Note that this file has a .Rmd extension.

* This R notebook contains all the code, output and answers for all of the 7 questions(and its sub-parts) in the task. This R Notebook (.Rmd file) is present in the root of the package directory. 

* Also all the helper (.R) scripts, other than this .Rmd file, can be found in the **R** sub-directory.

* Just make sure that you have all the R packages (mentioned in the "load_libraries" chunk in this R Notebook below) installed on your system. 

* Also, make sure that your paths are set as per your system. I have used relative paths in the code, but still it is good to have this as a Sanity check before running the code.

* Once you have followed all of the above steps, please continue reading below on how to use this R Notebook.


# How to use this R Markdown notebook? 

* You can preview this notebook using the **Preview** button, which will show you rendered HTML copy of the contents of the editor. 

* The other option is to knit this notebook into a neat PDF, which you can do using the **Knit** button.
 
* Unlike **Knit**, **Preview** does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed. So, when you use **Preview**, please make sure that you have once run all the chunks of code in the editor. Once you run all chunks and then preview, the resulting html output will show all code and all output (plots, tables, etc).

* This notebook contains all code, output and answers, for all of the 7 Questions (and all its sub-parts). By that I mean, it also contain answers to theory questions (ones in which I am asked about my observations and insights, e.g. Q7:part-3).

* I have also attached a complete pre-knitted PDF (with all code, output, answers) in my submission files (along side this .Rmd file).

* Feel free to reach out to me at **aarshbatra.in@gmail.com**/8800592799 if you have any questions or run into any problems. I will quickly troubleshoot it for you.


```{r metadata, echo=TRUE, message=FALSE, warning=FALSE}

# metadata---------------------------------------------------------------------
# author: Aarsh Batra
# Start Date: October 07, 2021
# R version: 4.1.1 (2021-08-10)
# nickname: Kick Things
# Platform: x86_64-w64-mingw32 
# arch: x86_64
# Running under: Windows 10 x64 (build 18363)
# R Studio version info: 2021.09.0+351 "Ghost Orchid"
# e-mail: aarshbatra.in@gmail.com

```


```{r load-libraries, message=FALSE, warning=FALSE, include=FALSE}

# load libraries---------------------------------------------------------------

library(tidyverse)
library(knitr)
library(devtools)
library(stringr)
library(tidyr)
library(dplyr)
library(skimr)
library(magrittr)
library(data.table)
library(lubridate)
library(roxygen2)
library(testthat)
library(ggplot2)
library(readr)
library(readxl)
```

```{r load-entire-package, echo=TRUE, message=FALSE, warning=FALSE}

# loading the entire package--------------------------------------------------

devtools::load_all()

```


```{r read-raw-datasets, echo=TRUE, message=FALSE, warning=FALSE}

# read in raw .xlsx datasets into R--------------------------------------------

coupon_transactions_raw <- read_raw_xlsx_data("couponTransactions.xlsx")
 
 customer_scans_raw <- read_raw_xlsx_data("customerScans.xlsx")
                                          
 customer_user_raw <- read_raw_xlsx_data("customerUser.xlsx")
```

## Exploratory Data Analysis

* Here I am getting to know the data sets after which I will proceed to 
answering the questions.

```{r exploratory-data-analysis-question-wise}

# exploring coupon_transaction_raw dataset-------------------------------------

View(coupon_transactions_raw)

# getting a basic summary
skimr::skim(coupon_transactions_raw)

# number of unique customers
length(unique(coupon_transactions_raw$customerId)) # 14979

# number of unique couponUnlock dates
length(unique(coupon_transactions_raw$couponUnlockDate)) # 291

# number of unique couponId's
length(unique(coupon_transactions_raw$couponId)) # 328


# exploring customer_scans_raw dataset-----------------------------------------

View(customer_scans_raw)

skimr::skim(customer_scans_raw)

# max amount for billTotal column
max(customer_scans_raw$billTotal) # why is this too big? look into this.

# number of unique customers
length(unique(customer_scans_raw$customerId))

# number of unique scan log ids
length(unique(customer_scans_raw$scanlogId))

# number of unique stores
length(unique(customer_scans_raw$storeName))

# store with the maximum bill total
customer_scans_raw %>% 
  filter(billTotal == max(billTotal)) %>%
  select(storeName)

# exploring customer_user_raw data---------------------------------------------

View(customer_user_raw)

skimr::skim(customer_user_raw)

# number of unique customers
unique(length(customer_user_raw$customerId))

# number of unique tierId's 
length(unique(customer_user_raw$tierId))

# wrapping up exploratory data analysis with a few more queries-----------------
colnames_for_datasets_list <- list(coup_trans_col = colnames
                                   (coupon_transactions_raw),
                                cust_scans_col = colnames(customer_scans_raw), 
                              cust_user_col = colnames(customer_user_raw))

# one common column between coupon_transactions_raw and customer_scans_raw
sum(colnames_for_datasets_list[[2]] %in% 
      colnames_for_datasets_list[[1]])  # customerId

# two common columns between customer_scans_raw and customer_user_raw
sum(colnames_for_datasets_list[[3]] %in% 
      colnames_for_datasets_list[[2]]) # customerId, createdAt

# one common column between customer_user_raw and coupon_transactions_raw
sum(colnames_for_datasets_list[[3]] %in% 
      colnames_for_datasets_list[[1]]) # customerId
```

## Pre-processing data

* Given the exploratory data analysis above, we find that the datasets are in a
tidy format and are relatively clean so no pre-processing is necessary.

&nbsp

&nbsp

&nbsp


# Let's get to the answers: 


## Code and answer for Q1

* **Question 1**: How many Users have logged in after 1st September 
2020 till date? How many of those have Signed up in September 2019?


* Code
```{r Q1-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# number of users who have logged in after 1st September 2021, till date

customer_user_raw_Q1_subset <- customer_user_raw %>%
  select(customerId, createdAt, lastLogin, tierId) %>%
  filter(lastLogin > lubridate::as_datetime("2020-09-01")) %>%
  distinct()
 
customer_user_raw_Q1_subset

 num_users_log_in_after_sep2021 <- customer_user_raw_Q1_subset %>%
   nrow()                                
 
 num_users_log_in_after_sep2021 # answer to Q1Part-1 = 10,323 users


# Of the above 10,323 users, how many signed up in September, 2019.

 num_user_logInAfterSep2021_signedUpInSep2019 <- customer_user_raw_Q1_subset %>%
  dplyr::filter(lubridate::month(createdAt) == 09, lubridate::year(createdAt) == 2019) %>%
   nrow()

 num_user_logInAfterSep2021_signedUpInSep2019 # answer to Q2Part-2 = 209 users

```

* **Answer 1 (part 1)**: `r num_users_log_in_after_sep2021` users have logged in
after 1st September 2021, till date.

* **Answer 1 (part 2)**: Of the `r num_users_log_in_after_sep2021` users from
part 1 above, `r num_user_logInAfterSep2021_signedUpInSep2019` users have signed
up in September 2019.

* Please Note: In the absence of a data dictionary describing what each column 
means, I have made the following assumptions about the columns in the 
**customer_users_raw** dataset: I have assumed that  the **createdAt** column 
in the corresponds to the sign_up date column, and the **lastLogin** corresponds
to the login column. This might seem obvious, but it is still worth mentioning.

&nbsp

&nbsp

&nbsp

## Code and answer for Q2

* **Question 2:** How many users have earned points more than 2000?

```{r Q2-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# sanity check
sum(is.na(customer_user_raw$earnedPoints))

# Number of users who have earnedPoints more than 2000
num_users_earned_points_more_than_2000 <- customer_user_raw %>%
  dplyr::filter(earnedPoints > 2000) %>% 
  distinct() %>%
  nrow()                          

 num_users_earned_points_more_than_2000            # answer to Q2 = 1261

```

* **Answer 2:** `r num_users_earned_points_more_than_2000` users have earned
points more than 2000

&nbsp

&nbsp

&nbsp

## Code and answer for Q3

* **Question 3: ** From which stores has customer id ‘83’ scanned bills
in February 2020?

```{r Q3-answer-code, echo=TRUE, message=FALSE, warning=FALSE}
customer_scans_raw_Q3_subset <- customer_scans_raw %>%
  filter(customerId == 83, lubridate::month(createdAt) == 02, 
         lubridate::year(createdAt) == 2020) %>%
  dplyr::select(customerId, storeName, createdAt, image) %>%
  dplyr::group_by(storeName) %>%
  dplyr::summarise(numBillsScanned = length(unique(image))) %>%
  dplyr::mutate(customerId = 83, month = "February, 2020") %>%
  dplyr::select(customerId, everything())

```

* Answer to Q3: Below is a table, which lists the stores from which customer
id "83" scanned bills in February, 2020. It also lists the total number of 
unique bills scanned by customer Id "83" for each store. This information is 
useful in case more than one bill is scanned per store. 

```{r Q3-answer-table, echo=TRUE, message=FALSE, warning=FALSE}
knitr::kable(customer_scans_raw_Q3_subset)
```

* Please Note: In the absence of a data dictionary describing what each column 
means, I have made the following assumptions about the columns in the 
**customer_scans_raw** dataset: I have assumed that  the **createdAt** column 
in this dataset corresponds to the date at which the scan was created, and the 
**billDate** column corresponds to date on which the bill was generated. 
Also, there is a date within the image file names, because we do not know, what
that date represents, I haven't extracted or used it.

&nbsp

&nbsp

&nbsp


## Code and answer for Q4 

**Question 4**: How many unique users unlocked coupons on 10th September 2020?

```{r Q4-answer-code, echo=TRUE, message=FALSE, warning=FALSE}
coupon_transactions_raw_Q4_subset <- coupon_transactions_raw %>%
  filter(couponUnlockDate == lubridate::as_datetime("2020-09-10")) %>%
  group_by(customerId) %>%
  summarise(numUniqueCouponsUnlocked = length(unique(couponId))) %>%
  mutate(dateOnWhichCouponUnlocked = "September 10, 2020")

num_unique_users_unlocked_coupons_on_Sep102020 <- 
  nrow(coupon_transactions_raw_Q4_subset)     # answer to Q4 = 34 unique users.


```

* **Answer to Q4:** `r num_unique_users_unlocked_coupons_on_Sep102020` unique
users unlocked coupons on September 10, 2021.

* Below presented is a table that lists these unique users and also shows 
the number of unique coupons unlocked by each one of them on September 10, 2021.

```{r Q4-answer-table, echo=TRUE, message=FALSE, warning=FALSE}

knitr::kable(coupon_transactions_raw_Q4_subset)

```


&nbsp

&nbsp

&nbsp


## Code and answer for Q5

* **Question 5: ** Create a pivot table as mentioned in the question description
in the [Question PDF file](https://github.com/AarshBatra/
UnifyndInterviewAssessment/blob/master/
Interview%20Assignment%20_%20Data%20Analytics.pdf)

```{r Q5-answer-code, echo=TRUE, message=FALSE, warning=FALSE}

# sanity checks (for understanding purposes only, these sanity check variables
# are not used in code)
foo <- dplyr::left_join(x = coupon_transactions_raw, y = customer_user_raw, by = c("customerId" = "customerId"))
sum(coupon_transactions_raw$customerId %in% customer_user_raw$customerId)
sum(!(customer_user_raw$customerId %in% coupon_transactions_raw$customerId))        

foo1Ind <- customer_user_raw$customerId %in% coupon_transactions_raw$customerId
foo1Val <- customer_user_raw$customerId[foo1Ind]
nrow(filter(coupon_transactions_raw, customerId %in% foo1Val))


# First: inner join the "customer_user_raw" and "coupon_transaction_raw data by 
# the "customerId" column as a KEY

customer_user_coupon_join_Q5 <- dplyr::left_join(x = customer_user_raw, y = coupon_transactions_raw, by = "customerId")

# removing duplicate rows
customer_user_coupon_join_Q5_unique <-  customer_user_coupon_join_Q5[!duplicated(customer_user_coupon_join_Q5), ]

# create Pivot table, by using tierId  as the "group" column
pivot_table_by_tier_Q5 <- customer_user_coupon_join_Q5_unique %>%
  dplyr::group_by(tierId) %>%
  dplyr::summarise(numUniqueUsersInEachTier = length(unique(customerId)),
            totalCouponsUnlocked = sum(!is.na(couponUnlockDate)),
            averageEarnedPoints = mean(earnedPoints, na.rm = TRUE), 
            averageBurnedPoints = mean(burnedPoints, na.rm = TRUE))


```

* **Answer 5:** Pivot Table for Q5

```{r Q5-answer-pivot-table }
knitr::kable(pivot_table_by_tier_Q5)
```

## Q6 Code and answer

* **Question 6:** Create a cohort of users with the following conditions and 
answer the following questions:(Scan Count > 4 && Coupon Transaction Count > 2)

  * 1. What’s the tier distribution of these users?
  * 2. What’s the gender distribution of these users?
  * 3. Which 5 stores have these users scanned the most from?
  * 4. Which source has the most users coming from in this cohort?
  * 5. Observe the behaviour of this cohort and write your observations and 
       insights.


* Getting the number and id's of customers that belong to the cohort whose 
scanCount > 4 and couponTransactionCount > 2
       
```{r Q6-answer-get-cohort, echo=TRUE, message=FALSE, warning=FALSE}

# get a vector of customerId's that satisfy the cohort conditions--------------
  
# customers with scan count > 4
customer_scans_raw_Q6_subset <- customer_scans_raw %>%
group_by(customerId) %>%
summarise(scanCount = sum(!is.na(unique(scanlogId)))) %>%
filter(scanCount > 4) 

# removing duplicates
customer_scans_raw_Q6_subset_unique <- customer_scans_raw_Q6_subset[
  !duplicated(customer_scans_raw_Q6_subset), ]

# For the customers whose scan count is greater than 4, select those whose
# coupon transaction count > 2.

# creating a subset of data that corresponds to those customers whose 
# scan count > 4
coupon_transactions_raw_Q6_subset <- coupon_transactions_raw %>%
  filter(customerId %in% customer_scans_raw_Q6_subset_unique$customerId) 

# removing any duplicate rows
coupon_transactions_raw_Q6_subset_unique <-  coupon_transactions_raw_Q6_subset[!duplicated
            (coupon_transactions_raw_Q6_subset), ]

# dataset containing customers whose "scanCount" > 4 and couponTransactionCount
# is > 2
coupon_transactions_raw_Q6_subset_unique %>% 
  group_by(customerId) %>%
  summarise(couponTransactionCount = sum(!is.na(couponUnlockDate))) %>%
  filter(couponTransactionCount > 2)

# putting the cohort customers (that satisfy the cohort definition) into a 
# vector

cohort_customers <- coupon_transactions_raw_Q6_subset_unique$customerId


```

* Given the above calculations, the cohort whose scanCount > 4 and
couponTransactionCount > 2, contain a total of `r cohort_customers` customers.
These customers are stored in the vector named **cohort_customers**. Now, I 
will use this information to answer parts 1 to 5 of Q6. For each part, I will
first present the code and then its answer (figure/table/etc).

* **Code and Answer to Question 6: Part-1**

```{r Q6-answer-part1, echo=TRUE, message=FALSE, warning=FALSE}

```






